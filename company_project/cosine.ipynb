{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/law.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. &lt;개정 2005. 10. 20.&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>제1조의2(소방기술민원센터의 설치ㆍ운영) ① 소방청장 또는 소방본부장은 「소방기본법...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>② 소방기술민원센터는 센터장을 포함하여 18명 이내로 구성한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>③ 소방기술민원센터는 다음 각 호의 업무를 수행한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. 소방시설, 소방공사와 위험물 안전관리 등과 관련된 법령해석 등의 민원(이하 “...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2. 소방기술민원과 관련된 질의회신집 및 해설서 발간</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3. 소방기술민원과 관련된 정보시스템의 운영ㆍ관리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4. 소방기술민원과 관련된 현장 확인 및 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5. 그 밖에 소방기술민원과 관련된 업무로서 소방청장 또는 소방본부장이 필요하다고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>④ 소방청장 또는 소방본부장은 소방기술민원센터의 업무수행을 위하여 필요하다고 인정하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>⑤ 제1항부터 제4항까지에서 규정한 사항 외에 소방기술민원센터의 설치ㆍ운영에 필요한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[본조신설 2022. 1. 4.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[종전 제1조의2는 제1조의3으로 이동 &lt;2022. 1. 4.&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>제1조의3(소방업무에 관한 종합계획 및 세부계획의 수립ㆍ시행) ① 소방청장은 법 제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>② 법 제6조제2항제7호에서 “대통령령으로 정하는 사항”이란 다음 각 호의 사항을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1. 재난ㆍ재해 환경 변화에 따른 소방업무에 필요한 대응 체계 마련</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2. 장애인, 노인, 임산부, 영유아 및 어린이 등 이동이 어려운 사람을 대상으로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>③ 특별시장ㆍ광역시장ㆍ특별자치시장ㆍ도지사 또는 특별자치도지사(이하 “시ㆍ도지사”라 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[본조신설 2016. 10. 25.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[제1조의2에서 이동 &lt;2022. 1. 4.&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>제2조(국고보조 대상사업의 범위와 기준보조율) ①법 제9조제2항에 따른 국고보조 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1. 다음 각 목의 소방활동장비와 설비의 구입 및 설치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>가. 소방자동차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>나. 소방헬리콥터 및 소방정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>다. 소방전용통신설비 및 전산설비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>라. 그 밖에 방화복 등 소방활동에 필요한 소방장비</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2. 소방관서용 청사의 건축(「건축법」 제2조제1항제8호에 따른 건축을 말한다)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>② 제1항제1호에 따른 소방활동장비 및 설비의 종류와 규격은 행정안전부령으로 정한다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>③ 제1항에 따른 국고보조 대상사업의 기준보조율은 「보조금 관리에 관한 법률 시행령...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[제목개정 2011. 11. 30.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>제2조의2(비상소화장치의 설치대상 지역) 법 제10조제2항에서 “대통령령으로 정하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1. 「화재의 예방 및 안전관리에 관한 법률」 제18조제1항에 따라 지정된 화재경계지구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2. 시ㆍ도지사가 법 제10조제2항에 따른 비상소화장치의 설치가 필요하다고 인정하는 지역</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[본조신설 2018. 6. 26.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[종전 제2조의2는 제2조의3으로 이동 &lt;2018. 6. 26.&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>제2조의3(소방력의 동원) ① 법 제11조의2제3항 및 제4항에 따라 동원된 소방력...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>② 법 제11조의2제3항 및 제4항에 따라 동원된 민간 소방 인력이 소방활동을 수행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>③ 제1항 및 제2항에서 규정한 사항 외에 법 제11조의2에 따라 동원된 소방력의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[본조신설 2011. 11. 30.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[제2조의2에서 이동 &lt;2018. 6. 26.&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>\n",
       "0   제1조의2(소방기술민원센터의 설치ㆍ운영) ① 소방청장 또는 소방본부장은 「소방기본법...                               \n",
       "1                 ② 소방기술민원센터는 센터장을 포함하여 18명 이내로 구성한다.                               \n",
       "2                       ③ 소방기술민원센터는 다음 각 호의 업무를 수행한다.                               \n",
       "3   1. 소방시설, 소방공사와 위험물 안전관리 등과 관련된 법령해석 등의 민원(이하 “...                               \n",
       "4                       2. 소방기술민원과 관련된 질의회신집 및 해설서 발간                               \n",
       "5                         3. 소방기술민원과 관련된 정보시스템의 운영ㆍ관리                               \n",
       "6                           4. 소방기술민원과 관련된 현장 확인 및 처리                               \n",
       "7   5. 그 밖에 소방기술민원과 관련된 업무로서 소방청장 또는 소방본부장이 필요하다고 ...                               \n",
       "8   ④ 소방청장 또는 소방본부장은 소방기술민원센터의 업무수행을 위하여 필요하다고 인정하...                               \n",
       "9   ⑤ 제1항부터 제4항까지에서 규정한 사항 외에 소방기술민원센터의 설치ㆍ운영에 필요한...                               \n",
       "10                                 [본조신설 2022. 1. 4.]                               \n",
       "11               [종전 제1조의2는 제1조의3으로 이동 <2022. 1. 4.>]                               \n",
       "12  제1조의3(소방업무에 관한 종합계획 및 세부계획의 수립ㆍ시행) ① 소방청장은 법 제...                               \n",
       "13  ② 법 제6조제2항제7호에서 “대통령령으로 정하는 사항”이란 다음 각 호의 사항을 ...                               \n",
       "14              1. 재난ㆍ재해 환경 변화에 따른 소방업무에 필요한 대응 체계 마련                               \n",
       "15  2. 장애인, 노인, 임산부, 영유아 및 어린이 등 이동이 어려운 사람을 대상으로 ...                               \n",
       "16  ③ 특별시장ㆍ광역시장ㆍ특별자치시장ㆍ도지사 또는 특별자치도지사(이하 “시ㆍ도지사”라 ...                               \n",
       "17                               [본조신설 2016. 10. 25.]                               \n",
       "18                         [제1조의2에서 이동 <2022. 1. 4.>]                               \n",
       "19  제2조(국고보조 대상사업의 범위와 기준보조율) ①법 제9조제2항에 따른 국고보조 대...                               \n",
       "20                     1. 다음 각 목의 소방활동장비와 설비의 구입 및 설치                               \n",
       "21                                           가. 소방자동차                               \n",
       "22                                    나. 소방헬리콥터 및 소방정                               \n",
       "23                                 다. 소방전용통신설비 및 전산설비                               \n",
       "24                       라. 그 밖에 방화복 등 소방활동에 필요한 소방장비                               \n",
       "25       2. 소방관서용 청사의 건축(「건축법」 제2조제1항제8호에 따른 건축을 말한다)                               \n",
       "26  ② 제1항제1호에 따른 소방활동장비 및 설비의 종류와 규격은 행정안전부령으로 정한다...                               \n",
       "27  ③ 제1항에 따른 국고보조 대상사업의 기준보조율은 「보조금 관리에 관한 법률 시행령...                               \n",
       "28                               [제목개정 2011. 11. 30.]                               \n",
       "29  제2조의2(비상소화장치의 설치대상 지역) 법 제10조제2항에서 “대통령령으로 정하는...                               \n",
       "30   1. 「화재의 예방 및 안전관리에 관한 법률」 제18조제1항에 따라 지정된 화재경계지구                               \n",
       "31  2. 시ㆍ도지사가 법 제10조제2항에 따른 비상소화장치의 설치가 필요하다고 인정하는 지역                               \n",
       "32                                [본조신설 2018. 6. 26.]                               \n",
       "33              [종전 제2조의2는 제2조의3으로 이동 <2018. 6. 26.>]                               \n",
       "34  제2조의3(소방력의 동원) ① 법 제11조의2제3항 및 제4항에 따라 동원된 소방력...                               \n",
       "35  ② 법 제11조의2제3항 및 제4항에 따라 동원된 민간 소방 인력이 소방활동을 수행...                               \n",
       "36  ③ 제1항 및 제2항에서 규정한 사항 외에 법 제11조의2에 따라 동원된 소방력의 ...                               \n",
       "37                               [본조신설 2011. 11. 30.]                               \n",
       "38                        [제2조의2에서 이동 <2018. 6. 26.>]                               "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "df['tokenized'] = df['제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>'].apply(lambda x: okt.morphs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [' '.join(words) for words in df['tokenized']]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(X)\n",
    "indices = pd.Series(df.index, index=df['제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>'])\n",
    "\n",
    "def get_similar_items(title, cosine_sim=cosine_sim, df=df, indices=indices, top_k=10):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_k+1]\n",
    "    item_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[item_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'제1조(목적)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '제1조(목적)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\2170241048.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_similar_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'제1조(목적)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\2442629782.py\u001b[0m in \u001b[0;36mget_similar_items\u001b[1;34m(title, cosine_sim, df, indices, top_k)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_similar_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0msim_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msim_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '제1조(목적)'"
     ]
    }
   ],
   "source": [
    "get_similar_items('제1조(목적)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\2824932055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjump\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Create a fixed-length vector for each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tokenize(document, jump=1):\n",
    "    tokens = document.split()\n",
    "    pairs = []\n",
    "    for i in range(len(tokens) - jump):\n",
    "        pairs.append(tokens[i:i+jump+1])\n",
    "    return pairs\n",
    "\n",
    "documents = [\"I like apples\", \"I like bananas\", \"I like bananas I like bananas\"]\n",
    "\n",
    "# Create a set of all possible tokens in the corpus\n",
    "tokens = set()\n",
    "for document in documents:\n",
    "    pairs = tokenize(document, jump=1)\n",
    "    for pair in pairs:\n",
    "        tokens.add(pair)\n",
    "\n",
    "# Create a fixed-length vector for each document\n",
    "vectors = []\n",
    "for document in documents:\n",
    "    pairs = tokenize(document, jump=1)\n",
    "    vector = []\n",
    "    for token in tokens:\n",
    "        count = pairs.count(token)\n",
    "        vector.append(count)\n",
    "    vectors.append(vector)\n",
    "\n",
    "# Compute the cosine similarity between each pair of documents\n",
    "for i in range(len(documents)):\n",
    "    for j in range(i+1, len(documents)):\n",
    "        similarity = np.dot(vectors[i], vectors[j]) / (np.linalg.norm(vectors[i]) * np.linalg.norm(vectors[j]))\n",
    "        print(f\"Similarity between Document {i+1} and Document {j+1}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1과 문서2의 유사도 : 0.6666666666666667\n",
      "문서 1과 문서3의 유사도 : 0.6666666666666667\n",
      "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(A, B):\n",
    "  return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "doc1 = np.array([0,1,1,1])\n",
    "doc2 = np.array([1,0,1,1])\n",
    "doc3 = np.array([2,0,2,2])\n",
    "\n",
    "print('문서 1과 문서2의 유사도 :',cos_sim(doc1, doc2))\n",
    "print('문서 1과 문서3의 유사도 :',cos_sim(doc1, doc3))\n",
    "print('문서 2와 문서3의 유사도 :',cos_sim(doc2, doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = ['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
    "set2 = ['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n",
    "union = set(set1).union(set(set2)) #두 집합의 합집합\n",
    "intersection = set(set1).intersection(set(set2))  #두 집합의 교집합\n",
    "len(intersection)/len(union)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝을 이용한 유사도분석 참고 코드"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계 학습을 사용하여 텍스트 간의 유사성을 분석하기 위해 다양한 자연어 처리(NLP) 기술을 사용할 수 있습니다.\n",
    "시작하기 위한 몇 가지 단계는 다음과 같습니다.\n",
    "\n",
    "\n",
    "\n",
    "텍스트 전처리: 텍스트 간의 유사성을 분석하기 전에 텍스트를 전처리해야 합니다.\n",
    "여기에는 일반적으로 중지 단어, 구두점 및 기타 영숫자가 아닌 문자를 제거하는 작업이 포함됩니다.\n",
    "텍스트를 개별 단어나 구로 토큰화해야 할 수도 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "텍스트 벡터화: 텍스트를 전처리한 후에는 기계 학습에 사용할 수 있는 수치 표현으로 변환해야 합니다.\n",
    "일반적인 접근 방식 중 하나는 CountVectorizer 또는 TF-IDF(term frequency-inverse document frequency)와 같은 벡터화 기술을 사용하는 것입니다.\n",
    "\n",
    "\n",
    "유사성 메트릭 선택: 다음으로 벡터화된 텍스트 간의 유사성을 측정할 유사성 메트릭을 선택해야 합니다.\n",
    "일반적인 유사성 메트릭에는 코사인 유사성, Jaccard 유사성 및 유클리드 거리가 포함됩니다.\n",
    "기계 학습 알고리즘 선택: 마지막으로 벡터화된 텍스트와 유사성 메트릭을 사용하여 유사성 분석을 수행할 수 있는 기계 학습 알고리즘을 선택해야 합니다. 널리 사용되는 알고리즘에는 KNN(k-nearest Neighbors), SVM(Support Vector Machine) 및 신경망이 포함됩니다.\n",
    "\n",
    "\n",
    "\n",
    "다음은 코사인 유사성과 KNN을 사용하여 텍스트 간의 유사성 분석을 수행하는 방법을 보여주는 Python의 몇 가지 예제 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\756431517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'brute'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cosine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m# Print the most similar texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    728\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 2"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Example texts to analyze similarity\n",
    "texts = [\n",
    "    \"\"\"제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>\n",
    "제1조의2(소방기술민원센터의 설치ㆍ운영) ① 소방청장 또는 소방본부장은 「소방기본법」(이하 “법”이라 한다) 제4조의2제1항에 따른 소방기술민원센터(이하 “소방기술민원센터”라 한다)를 소방청 또는 소방본부에 각각 설치ㆍ운영한다.\n",
    "② 소방기술민원센터는 센터장을 포함하여 18명 이내로 구성한다.\n",
    "③ 소방기술민원센터는 다음 각 호의 업무를 수행한다.\n",
    "\"1. 소방시설, 소방공사와 위험물 안전관리 등과 관련된 법령해석 등의 민원(이하 “소방기술민원”이라 한다)의 처리\"\n",
    "2. 소방기술민원과 관련된 질의회신집 및 해설서 발간\n",
    "3. 소방기술민원과 관련된 정보시스템의 운영ㆍ관리\n",
    "4. 소방기술민원과 관련된 현장 확인 및 처리\n",
    "5. 그 밖에 소방기술민원과 관련된 업무로서 소방청장 또는 소방본부장이 필요하다고 인정하여 지시하는 업무\n",
    "④ 소방청장 또는 소방본부장은 소방기술민원센터의 업무수행을 위하여 필요하다고 인정하는 경우에는 관계 기관의 장에게 소속 공무원 또는 직원의 파견을 요청할 수 있다.\n",
    "\"⑤ 제1항부터 제4항까지에서 규정한 사항 외에 소방기술민원센터의 설치ㆍ운영에 필요한 사항은 소방청에 설치하는 경우에는 소방청장이 정하고, 소방본부에 설치하는 경우에는 해당 특별시ㆍ광역시ㆍ특별자치시ㆍ도 또는 특별자치도(이하 “시ㆍ도”라 한다)의 규칙으로 정한다.\"\n",
    "[본조신설 2022. 1. 4.]\n",
    "[종전 제1조의2는 제1조의3으로 이동 <2022. 1. 4.>]\n",
    "\"제1조의3(소방업무에 관한 종합계획 및 세부계획의 수립ㆍ시행) ① 소방청장은 법 제6조제1항에 따른 소방업무에 관한 종합계획을 관계 중앙행정기관의 장과의 협의를 거쳐 계획 시행 전년도 10월 31일까지 수립해야 한다. <개정 2017. 7. 26., 2022. 1. 4.>\"\n",
    "② 법 제6조제2항제7호에서 “대통령령으로 정하는 사항”이란 다음 각 호의 사항을 말한다.\n",
    "1. 재난ㆍ재해 환경 변화에 따른 소방업무에 필요한 대응 체계 마련\n",
    "\"2. 장애인, 노인, 임산부, 영유아 및 어린이 등 이동이 어려운 사람을 대상으로 한 소방활동에 필요한 조치\"\n",
    "\"③ 특별시장ㆍ광역시장ㆍ특별자치시장ㆍ도지사 또는 특별자치도지사(이하 “시ㆍ도지사”라 한다)는 법 제6조제4항에 따른 종합계획의 시행에 필요한 세부계획을 계획 시행 전년도 12월 31일까지 수립하여 소방청장에게 제출하여야 한다. <개정 2017. 7. 26., 2018. 6. 26.>\"\n",
    "[본조신설 2016. 10. 25.]\n",
    "[제1조의2에서 이동 <2022. 1. 4.>]\n",
    "\"제2조(국고보조 대상사업의 범위와 기준보조율) ①법 제9조제2항에 따른 국고보조 대상사업의 범위는 다음 각 호와 같다. <개정 2005. 10. 20., 2011. 11. 30., 2016. 10. 25.>\"\n",
    "1. 다음 각 목의 소방활동장비와 설비의 구입 및 설치\n",
    "가. 소방자동차\n",
    "나. 소방헬리콥터 및 소방정\n",
    "다. 소방전용통신설비 및 전산설비\n",
    "라. 그 밖에 방화복 등 소방활동에 필요한 소방장비\n",
    "2. 소방관서용 청사의 건축(「건축법」 제2조제1항제8호에 따른 건축을 말한다)\n",
    "\"② 제1항제1호에 따른 소방활동장비 및 설비의 종류와 규격은 행정안전부령으로 정한다. <개정 2011. 11. 30., 2013. 3. 23., 2014. 11. 19., 2017. 7. 26.>\"\n",
    "③ 제1항에 따른 국고보조 대상사업의 기준보조율은 「보조금 관리에 관한 법률 시행령」에서 정하는 바에 따른다. <개정 2011. 11. 30.>\n",
    "[제목개정 2011. 11. 30.]\n",
    "제2조의2(비상소화장치의 설치대상 지역) 법 제10조제2항에서 “대통령령으로 정하는 지역”이란 다음 각 호의 어느 하나에 해당하는 지역을 말한다. <개정 2022. 11. 29.>\n",
    "1. 「화재의 예방 및 안전관리에 관한 법률」 제18조제1항에 따라 지정된 화재경계지구\n",
    "2. 시ㆍ도지사가 법 제10조제2항에 따른 비상소화장치의 설치가 필요하다고 인정하는 지역\n",
    "[본조신설 2018. 6. 26.]\n",
    "[종전 제2조의2는 제2조의3으로 이동 <2018. 6. 26.>]\n",
    "\"제2조의3(소방력의 동원) ① 법 제11조의2제3항 및 제4항에 따라 동원된 소방력의 소방활동 수행 과정에서 발생하는 경비는 화재, 재난ㆍ재해나 그 밖의 구조ㆍ구급이 필요한 상황이 발생한 시ㆍ도에서 부담하는 것을 원칙으로 하며, 구체적인 내용은 해당 시ㆍ도가 서로 협의하여 정한다. <개정 2022. 1. 4.>\"\n",
    "\"② 법 제11조의2제3항 및 제4항에 따라 동원된 민간 소방 인력이 소방활동을 수행하다가 사망하거나 부상을 입은 경우 화재, 재난ㆍ재해 또는 그 밖의 구조ㆍ구급이 필요한 상황이 발생한 시ㆍ도가 해당 시ㆍ도의 조례로 정하는 바에 따라 보상한다.\"\n",
    "\"③ 제1항 및 제2항에서 규정한 사항 외에 법 제11조의2에 따라 동원된 소방력의 운용과 관련하여 필요한 사항은 소방청장이 정한다. <개정 2014. 11. 19., 2017. 7. 26.>\"\n",
    "[본조신설 2011. 11. 30.]\n",
    "[제2조의2에서 이동 <2018. 6. 26.>]\"\"\"\n",
    "]\n",
    "\n",
    "# Vectorize the texts\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_similarities = cosine_similarity(vectors)\n",
    "\n",
    "# Use KNN to find the most similar texts\n",
    "k = 2\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='cosine').fit(vectors)\n",
    "distances, indices = nbrs.kneighbors(vectors)\n",
    "\n",
    "# Print the most similar texts\n",
    "for i, text in enumerate(texts):\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Most similar texts:\")\n",
    "    for j in indices[i][1:]:\n",
    "        print(texts[j])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Purpose: The purpose of this Decree is to prescribe the matters entrusted in the 「Framework Act on Fire Protection」 and matters necessary for its implementation. <Amended 2005. 10. 20.>\n",
      "Article Establishment and Operation of Civil Service Center for Fire Protection: Technical Civil Complaint Center”) shall be installed and operated at the Fire Administration or the Fire Headquarters, respectively.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Article 1 (Purpose) The purpose of this Decree is to prescribe the matters entrusted in the 「Framework Act on Fire Protection」 and matters necessary for its implementation. <Amended 2005. 10. 20.>\\n\\nArticle 1-2 (Establishment and Operation of Civil Service Center for Fire Protection) Technical Civil Complaint Center”) shall be installed and operated at the Fire Administration or the Fire Headquarters, respectively.\\n② The Firefighting Technical Civil Service Center shall consist of up to 18 people, including the head of the center.\"\n",
    "\n",
    "# Define regular expression patterns to match article numbers and their corresponding text\n",
    "article_pattern = r\"Article\\s\\d+(?:-\\d+)?\\s*\\((.*?)\\)\\s*(.*)\"\n",
    "\n",
    "# Find all matches of article numbers and their corresponding text in the text\n",
    "matches = re.findall(article_pattern, text)\n",
    "\n",
    "# Print the results\n",
    "for match in matches:\n",
    "    article_number = match[0]\n",
    "    article_text = match[1]\n",
    "    print(f\"Article {article_number}: {article_text}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 방법"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥 러닝을 사용하여 텍스트 간의 유사성을 측정하려면 텍스트 데이터의 임베딩(벡터 표현)을 생성한\n",
    "다음 이러한 임베딩 간의 거리 또는 유사성을 계산해야 합니다.\n",
    "다음은 딥 러닝을 사용하여 텍스트 유사성을 측정하는 몇 가지 일반적인 접근 방식입니다.\n",
    "\n",
    "\n",
    "단어 임베딩: 단어 임베딩은 의미론적 의미를 포착하는 개별 단어의 벡터 표현입니다.\n",
    "텍스트에서 단어의 임베딩을 생성하는 데 사용할 수 있는 몇 가지 사전 훈련된 단어 임베딩 모델(예: Word2Vec 및 GloVe)이 있습니다.\n",
    "단어 임베딩을 사용하여 텍스트 유사성을 측정하는 일반적인 방법 중 하나는 각 텍스트에서 단어\n",
    "임베딩의 평균을 낸 다음 결과 벡터 간의 코사인 유사성을 계산하는 것입니다.\n",
    "\n",
    "\n",
    "문장 임베딩: 문장 임베딩은 의미론적 의미를 포착하는 전체 문장의 벡터 표현입니다. 전체 문장의 임베딩을 생성하는 데 사용할 수 있는 몇 가지 사전 훈련된 문장 임베딩 모델(예: Universal Sentence Encoder 및 BERT)이 있습니다. 문장 임베딩을 사용하여 텍스트 유사성을 측정하는 일반적인 방법 중 하나는 두 문장의 임베딩 간의 코사인 유사성을 계산하는 것입니다.\n",
    "\n",
    "\n",
    "샴 신경망: 샴 신경망은 두 입력(예: 두 텍스트) 간의 유사성을 비교하는 방법을 학습할 수 있는 일종의 신경망입니다. 일반적으로 동일한 가중치를 공유하고 두 입력의 임베딩을 생성하도록 훈련된 두 개의 동일한 신경망을 포함합니다. 그런 다음 임베딩은 거리 메트릭(예: 코사인 유사성)을 사용하여 비교되고 네트워크는 예측된 유사성과 실제 유사성 간의 차이를 최소화하도록 훈련됩니다.\n",
    "\n",
    "\n",
    "Transformer 기반 모델: Transformer 기반 모델(예: BERT 및 RoBERTa)은 개별 단어 및 문장 외에도 전체 문서(예: 단락 또는 기사)의 임베딩을 생성할 수 있는 일종의 딥 러닝 모델입니다. 이 모델은 두 텍스트의 임베딩을 생성한 다음 이들 사이의 코사인 유사성을 계산하는 데 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "다음은 Universal Sentence Encoder를 사용하여 텍스트 유사성을 측정하기 위한 Python 코드의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\166851728.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load the Universal Sentence Encoder model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "\n",
    "# Load the Universal Sentence Encoder model\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "\n",
    "# Define two example texts to compare\n",
    "text1 = \"The quick brown fox jumps over the lazy dog\"\n",
    "text2 = \"A fox is jumping over a dog\"\n",
    "\n",
    "# Generate embeddings for the example texts\n",
    "embedding1 = embed([text1])[0]\n",
    "embedding2 = embed([text2])[0]\n",
    "\n",
    "# Compute the similarity between the embeddings\n",
    "similarity = 1 - (tf.reduce_sum(tf.square(embedding1 - embedding2)) / 2)\n",
    "\n",
    "# Print the similarity score\n",
    "print(f\"Similarity score: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\y2kjd/nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\y2kjd\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\2305710966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m 5. 그 밖에 소방기술민원과 관련된 업무로서 소방청장 또는 소방본부장이 필요하다고 인정하여 지시하는 업무\"\"\"\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjaccard_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Jaccard similarity coefficient:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29952\\2305710966.py\u001b[0m in \u001b[0;36mjaccard_similarity\u001b[1;34m(text1, text2)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjaccard_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# tokenize the texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtokens1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtokens2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\y2kjd\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\y2kjd/nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\y2kjd\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\y2kjd\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# define function to calculate Jaccard similarity coefficient\n",
    "def jaccard_similarity(text1, text2):\n",
    "    # tokenize the texts\n",
    "    tokens1 = set(word_tokenize(text1.lower()))\n",
    "    tokens2 = set(word_tokenize(text2.lower()))\n",
    "    \n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('korean'))\n",
    "    tokens1 = [token for token in tokens1 if token not in stop_words]\n",
    "    tokens2 = [token for token in tokens2 if token not in stop_words]\n",
    "    \n",
    "    # calculate Jaccard similarity coefficient\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1.union(tokens2))\n",
    "    jaccard_similarity = intersection / union\n",
    "    \n",
    "    return jaccard_similarity\n",
    "\n",
    "# test the function with text1 and text2\n",
    "text1 = \"\"\"제1조(목적) 이 영은 「소방기본법」에서 위임된 사항과 그 시행에 관하여 필요한 사항을 규정함을 목적으로 한다. <개정 2005. 10. 20.>\n",
    "제1조의2(소방기술민원센터의 설치ㆍ운영) ① 소방청장 또는 소방본부장은 「소방기본법」(이하 “법”이라 한다) 제4조의2제1항에 따른 소방기술민원센터(이하 “소방기술민원센터”라 한다)를 소방청 또는 소방본부에 각각 설치ㆍ운영한다.\n",
    "② 소방기술민원센터는 센터장을 포함하여 18명 이내로 구성한다.\"\"\"\n",
    "\n",
    "text2 = \"\"\"제1조의2(소방기술민원센터의 설치ㆍ운영) ① 소방청장 또는 소방본부장은 「소방기본법」(이하 “법”이라 한다) 제4조의2제1항에 따른 소방기술민원센터(이하 “소방기술민원센터”라 한다)를 소방청 또는 소방본부에 각각 설치ㆍ운영한다.\n",
    "\n",
    "② 소방기술민원센터는 센터장을 포함하여 18명 이내로 구성한다.\n",
    "\n",
    "③ 소방기술민원센터는 다음 각 호의 업무를 수행한다.\n",
    "\n",
    "1. 소방시설, 소방공사와 위험물 안전관리 등과 관련된 법령해석 등의 민원(이하 “소방기술민원”이라 한다)의 처리\n",
    "\n",
    "2. 소방기술민원과 관련된 질의회신집 및 해설서 발간\n",
    "\n",
    "3. 소방기술민원과 관련된 정보시스템의 운영ㆍ관리\n",
    "\n",
    "4. 소방기술민원과 관련된 현장 확인 및 처리\n",
    "\n",
    "5. 그 밖에 소방기술민원과 관련된 업무로서 소방청장 또는 소방본부장이 필요하다고 인정하여 지시하는 업무\"\"\"\n",
    "\n",
    "similarity = jaccard_similarity(text1, text2)\n",
    "print(\"Jaccard similarity coefficient:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 문서 간의 자카드 유사도: 0.09\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "def jaccard_similarity(set_a: Set[str], set_b: Set[str]) -> float:\n",
    "    intersection = len(set_a.intersection(set_b))\n",
    "    union = len(set_a.union(set_b))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "def tokenize_text(text: str) -> Set[str]:\n",
    "    # 기본적으로, 단어로 나눔으로써 문서를 토큰화합니다.\n",
    "    # 다른 토큰화 방법 또한 사용 가능합니다 (예: 형태소 분석기를 사용한 토큰화).\n",
    "    return set(text.split())\n",
    "\n",
    "def calculate_document_similarity(doc_a: str, doc_b: str) -> float:\n",
    "    tokens_a = tokenize_text(doc_a)\n",
    "    tokens_b = tokenize_text(doc_b)\n",
    "\n",
    "    return jaccard_similarity(tokens_a, tokens_b)\n",
    "\n",
    "# 예시 문서들\n",
    "doc1 = \"뤼튼 기술은 창조를 확장하기 위해 사람들을 도와주는 뤼튼 회사에서 만들어졌습니다.\"\n",
    "doc2 = \"뤼튼 회사는 사람들이 더 빠르고 쉽게 콘텐츠를 생성하도록 돕기 위해 높은 품질의 콘텐츠를 생성하는 데 기여했습니다.\"\n",
    "\n",
    "similarity = calculate_document_similarity(doc1, doc2)\n",
    "print(f\"두 문서 간의 자카드 유사도: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 문서 간의 자카드 유사도: 0.22\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Set\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "def jaccard_similarity(set_a: Set[str], set_b: Set[str]) -> float:\n",
    "    intersection = len(set_a.intersection(set_b))\n",
    "    union = len(set_a.union(set_b))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "def tokenize_text(text: str) -> Set[str]:\n",
    "    okt = Okt()\n",
    "    return set(okt.morphs(text))\n",
    "\n",
    "def calculate_document_similarity(doc_a: str, doc_b: str) -> float:\n",
    "    tokens_a = tokenize_text(doc_a)\n",
    "    tokens_b = tokenize_text(doc_b)\n",
    "\n",
    "    return jaccard_similarity(tokens_a, tokens_b)\n",
    "\n",
    "# 예시 문서들\n",
    "doc1 = \"뤼튼 기술은 창조를 확장하기 위해 사람들을 도와주는 뤼튼 회사에서 만들어졌습니다.\"\n",
    "doc2 = \"뤼튼 회사는 사람들이 더 빠르고 쉽게 콘텐츠를 생성하도록 돕기 위해 높은 품질의 콘텐츠를 생성하는 데 기여했습니다.\"\n",
    "\n",
    "similarity = calculate_document_similarity(doc1, doc2)\n",
    "print(f\"두 문서 간의 자카드 유사도: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
